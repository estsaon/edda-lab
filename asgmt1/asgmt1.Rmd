---
title: "Assignment 1"
author: "Peter Pan, Yuxiang Wang, Yancheng Zhuang"
date: "14 February 2021"
output: pdf_document
fontsize: 11pt
highlight: tango
header-includes:
   - \usepackage{bbm}
---

`r options(digits=3)`

## Exercise 1
<!--
The data set birthweight.txt contains the birthweights of 188 newborn babies. 
We are interested in finding the underlying (population) mean μ of birthweights.
-->

**a)** 
<!--
Check normality of the data. 
Compute a point estimate for μ. 
Derive, assuming normality (irrespective of your conclusion about normality od the data), 
a bounded 90% confidence interval for μ. 
-->

**b)** 
<!--
An expert claims that the mean birthweight is bigger than 2800, verify this claim by using a t-test.
What is the outcome of the test if you take α = 0.1? 
And other values of α?
-->

**c)** 
<!--
In the R-output of the test from b), also a confidence interval is given, 
but why is it different from the confidence interval found in a) and why is it one-sided?
-->

## Exercise 2
<!--
We study the power function of the two-sample t-test (see Section 1.9 of Assignment 0). 
For n=m=30, mu=180, nu=175 and sd=5, generate 1000 samples x=rnorm(n, mu, sd) and y=rnorm(m, nu, sd), 
and record the 1000 p-values for testing H0: mu=nu. 
You can evaluate the power (at point nu=175) of this t-test as fraction of p-values that are smaller than 0.05.
-->

**a)** 
<!--
Set n=m=30, mu=180 and sd=5. 
Calculate now the power of the t-test for every value of nu in the grid seq(175, 185, by=0.25). 
Plot the power as a function of nu.
-->

**b)** 
<!--
Set n=m=100, mu=180 and sd=5. 
Repeat the preceding exercise. 
Add the plot to the preceding plot.
-->

**c)** 
<!--
Set n=m=30, mu=180 and sd=15. 
Repeat the preceding exercise.
-->

**d)** 
<!--
Explain your findings.
-->

## Exercise 3
<!--
A telecommunication company has entered the market for mobile phones in a new country. 
The company's marketing manager conducts a survey of 200 new subscribers for mobile phones. 
The results of the survey are in the data set telephone.txt, 
which contains the first month bills X_1, ..., X_200, in euros.
-->

**a)** 
<!--
Make an appropriate plot of this data set. 
What marketing advice(s) would you give to the marketing manager? 
Are there any inconsistencies in the data? 
If so, try to fix these.
-->

We use histogram and QQ-plot to visualize the distribution of the data. 

```{r, fig.height=3, fig.width=6, fig.align='center'}
bills <- scan("telephone.txt", skip=2)
par(mfrow=c(1, 2))
hist(bills, prob=T)
qqnorm(bills)
```

From the plots we can see that the data don't follow the normal distribution. 
And we can roughly divide the data into three intervals. 
Firstly, the [0, 30] interval contains a large number of subscribers with low bill. 
Secondly, the [30, 70] interval contains the fewest users. 
Lastly, the [30, 120] interval contains a relatively big group of users. 
Based on the distribution, we advise that the company might consider on two types of pricing policies fow low-bill and high-bill users.
We don't find any inconsisteny in the data. 
The only bill worthing noticing is the bill with 0, but we think it is plausible that someone just didn't call or text that month.

**b)** 
<!--
By using a bootstrap test with the test statistic T = median(X_1, ..., X_200), 
test whether the data telephone.txt stems from the exponential distribution Exp(λ) with some λ from [0.01, 0.1].
-->

We let $\lambda$ to iterate from 0.01 to 0.1 by 0.001 to determine 
whether the data stem from the exponential distribution Exp($\lambda$) with some $\lambda$ from [0.01, 0.1]. 
Each of the simluations repeats 1000 times.

```{r}
T_val <- median(bills)
N <- length(bills)
B <- 1000
T_vals <- numeric(B)
lambdas <- seq(0.01, 0.1, by=0.001)
p_vals <- numeric(length(lambdas))

for (i in 1:length(lambdas)) {
    for (j in 1:B) {
        sampled_bills <- rexp(N, lambdas[i])
        T_vals[j] <- median(sampled_bills)
    }

    p_val_left <- sum(T_vals < T_val) / B
    p_val_right <- sum(T_vals > T_val) / B
    p_vals[i] <- 2 * min(p_val_left, p_val_right)
}
plot(lambdas, p_vals, type='p')
```

According to the plot, we can see that when $\lambda$ gets closer to `r lambdas[which.max(p_vals)]`, 
the $p$ can even reach more than 0.9. 
So the data must stem from the exponential distribution Exp($\lambda$) with some $\lambda$ from [0.01, 0.1].

**c)** 
<!--
Construct a 95% bootstrap confidence interval for the population median of the sample.
-->

Confidence interval should be $[2T - T^{*}_{(1-\alpha)}, 2T - T^{*}_{(\alpha)}]$, where confidence = $1 - 2\alpha$. 
We repeat the simulation for 1000 times.

```{r}
bootstrap_ci <- function(data, B, T, confidence) {
    T_val <- T(data)
    T_vals <- numeric(B)

    for (i in 1:B) {
        sampled_data <- sample(data, replace=TRUE)
        T_vals[i] <- median(sampled_data)
    }

    alpha <- (1 - confidence) / 2
    ci <- c(2 * T_val - quantile(T_vals, 1 - alpha), 
            2 * T_val - quantile(T_vals, alpha))
    return (ci)
}
ci <- bootstrap_ci(bills, 1000, median, 0.95)
```

So the 95% bootstrap confidence interval for the population median of the sample is [`r ci`].

**d)** 
<!--
Assuming X_1, ..., X_N ~ Exp(λ) and using the central limit theorem for the sample mean, 
estimate λ and construct again a 95% confidence interval for the population median. 
Comment on your findings.
-->
<!-- ref: https://rpubs.com/MLivingstone/CourseraInferentialStatsP1 -->

Using central limit theorem we consider that the sample mean follows normal distribution with a mean that matches the poplution mean. 
So we set up 1000 samples, each sampling samples 100 bills from the data. 
The mean of all 1000 samples then can be used to estimate $\lambda$. 

```{r}
B <- 1000
means <- numeric(B)

for (i in 1:B) {
    sampled_bills <- sample(bills, 100)
    means[i] <- mean(sampled_bills)
}
lambda <- 1 / mean(means)
```

We compute that $\lambda$ = `r lambda`. 
So using the $\lambda$ we computed, we construct again a 95% confidence interval for the population median.

```{r}
ci <- bootstrap_ci(rexp(length(bills), lambda), 1000, median, 0.95)
```

We get [`r ci`] this time.
Compare to the confidence interval we get in c), the confidence interval we get this time deviate slightly to the right.

**e)** 
<!--
Using an appropriate test, test the null hypothesis that the median bill is bigger or equal to 40 euro against 
the alternative that the median bill is smaller than 40 euro. 
Next, design and perform a test to check whether the fraction of the bills less than 10 euro is less than 25%.
-->
<!-- ref: https://cran.r-project.org/web/packages/distributions3/vignettes/one-sample-sign-tests.html -->

We use sign test to perform the test. 
For the first question, we set up $H_0$ as m $\geq$ 40.

```{r}
p_value <- binom.test(sum(bills > 40), length(bills), alternative="less")$p.value
```

We get $p$ = `r p_value`, so we reject $H_0$, that is to say the median bill is smaller than 40 euro. 
For the second question, we set up $H_0$ as $q_{0.25} \geq 10$.

```{r}
p_value <- binom.test(
    sum(bills > 10), length(bills), p=0.75, alternative="less"
)$p.value
```

We get $p$ = `r p_value`, so we don't reject $H_0$. 
The fraction of the bills less than 10 euro is less than 25%.

## Exercise 4
<!--
To study the effect of energy drink a sample of 24 high school pupils were randomized to drinking 
either a softdrink or an energy drink after running for 60 meters. 
After half an hour they were asked to run again. 
For both sprints they were asked to sprint as fast they could,  and the sprinting time was measured. 
The data is given in the file run.txt. 
[Courtesy class 5E, Stedelijk Gymnasium Leiden, 2010.]
-->

**a)** 
<!--
Disregarding the type of drink, test whether the run times before drink and after are correlated. 
-->

**b)** 
<!--
Test separately, for both the softdrink and the energy drink conditions, 
whether there is a difference in speed in the two running tasks.
-->

**c)** 
<!--
For each pupil compute the time difference between the two running tasks. 
Test whether these time differences are effected by the type of drink.
-->

**d)** 
<!--
Can you think of a plausible objection to the design of the experiment in b) 
if the main aim was to test whether drinking the energy drink speeds up the running? 
Is there a similar objection to the design of the experiment in c)? 
Comment on all your findings in this exercise.
-->

## Exercise 5
<!--
The dataset chickwts is a data frame included in the standard R installation, to view it, type chickwts at the R prompt. 
This data frame contains 71 observations on newly-hatched chicks which were randomly allocated among six groups. 
Each group was given a different feed supplement for six weeks, after which their weight (in grams) was measured. 
The data frame consists of a numeric column giving the weights, and a factor column giving the name of the feed supplement.
-->

**a)** 
<!--
Test whether the distributions of the chicken weights for meatmeal and sunflower groups are different by performing three tests: 
the two samples t-test (argue whether the data are paired or not), the
Mann-Whitney test and the Kolmogorov-Smirnov test. 
Comment on your findings.
-->

**b)** 
<!--
Conduct a one-way ANOVA to determine whether the type of feed supplement has an effect on the weight of the chicks. 
Give the estimated chick weights for each of the six feed supplements. 
What is the best feed supplement?
-->

**c)** 
<!--
Check the ANOVA model assumptions by using relevant diagnostic tools.
-->

**d)** 
<!--
Does the Kruskal-Wallis test arrive at the same conclusion about the effect of feed supplement as the test in b)? 
Explain possible differences between conclusions of the Kruskal-Wallis and ANOVA tests.
-->
